# drug-data-pipeline

This repository is a data pipeline project designed to process and analyze drug-related data from various sources.

## CrÃ©er un environnement virtuel Python 3.11.x sous WSL

Pour crÃ©er un environnement virtuel Python 3.11.x sous WSL (Windows Subsystem for Linux), suivez les Ã©tapes suivantes :

### VÃ©rifier la version de Python installÃ©e

- Ouvrez votre terminal WSL.
- ExÃ©cutez la commande suivante pour vÃ©rifier la version de Python :


<pre><code>python --version</code></pre>


Si la version affichÃ©e est infÃ©rieure Ã  3.11.x, vous devrez installer Python 3.11.x.

### Installer Python 3.11.x

- Ajoutez le dÃ©pÃ´t de paquets de Python :

<pre><code>sudo add-apt-repository ppa:deadsnakes/ppa</code></pre>


- Mettez Ã  jour la liste des paquets :

<pre><code>sudo apt update</code></pre>

- Installez Python 3.11 :

<pre><code>sudo apt install python3.11</code></pre>


- VÃ©rifiez l'installation :

<pre><code>python3.11 --version</code></pre>


### Installer python3.11-venv

- Installez le module venv pour Python 3.11 :

<pre><code>sudo apt install python3.11-venv</code></pre>


### CrÃ©er un environnement virtuel

- Naviguez vers le rÃ©pertoire de votre projet :

<pre><code>cd /chemin/vers/votre/projet</code></pre>
 Exemple : *cd /home/user/data_pipeline_project*

<pre><code>python3.11 -m venv nom_de_votre_env</code></pre>
 Exemple : *python3.11 -m venv venv*

Remplacez `nom_de_votre_env` par le nom souhaitÃ© pour votre environnement virtuel.

- Activez l'environnement :

<pre><code>source nom_de_votre_env/bin/activate</code></pre>
 Exemple: *source venv/bin/activate*

Vous devriez voir le nom de l'environnement virtuel apparaÃ®tre dans votre invite de commande, indiquant que l'environnement est activÃ©.

### Remarques

- Assurez-vous que votre systÃ¨me est Ã  jour avant d'installer de nouveaux paquets :

<pre><code>sudo apt update && sudo apt upgrade</code></pre>


## Installer les dÃ©pendances listÃ©es dans un fichier requirements.txt

Pour installer les dÃ©pendances listÃ©es dans un fichier `requirements.txt` sous Python 3.11.x, suivez les Ã©tapes suivantes :

### Assurez-vous que votre environnement virtuel est activÃ©

- Si vous n'avez pas encore crÃ©Ã© d'environnement virtuel, crÃ©ez-en un avec la commande :

<pre><code>python3.11 -m venv mon_env</code></pre>
Exemple : *python3.11 -m venv venv*


Remplacez `mon_env` par le nom souhaitÃ© pour votre environnement virtuel.

- Activez l'environnement virtuel :

<pre><code>source mon_env/bin/activate</code></pre>
Exemple : *source venv/bin/activate*

Vous devriez voir le nom de l'environnement virtuel apparaÃ®tre dans votre invite de commande, indiquant que l'environnement est activÃ©.

### Installez les dÃ©pendances Ã  partir du fichier requirements.txt

- Assurez-vous que le fichier `requirements.txt` est prÃ©sent dans le rÃ©pertoire courant.

- Installez les packages listÃ©s dans le fichier :

<pre><code>pip install -r requirements.txt</code></pre>


Cette commande lira le fichier `requirements.txt` et installera toutes les dÃ©pendances spÃ©cifiÃ©es.

### Remarque

- Si vous rencontrez des problÃ¨mes lors de l'installation des packages, il est possible que votre systÃ¨me empÃªche l'installation de packages Python non gÃ©rÃ©s par le systÃ¨me. Pour contourner ce problÃ¨me, vous pouvez utiliser l'option `--break-system-packages` avec pip :

<pre><code>pip install --break-system-packages -r requirements.txt</code></pre>


## ExÃ©cuter pytest

Pour exÃ©cuter pytest, identifiez le rÃ©pertoire src :

<pre><code>export PYTHONPATH="/home/user/myproject:$PYTHONPATH"</code></pre>
Exemple : *export PYTHONPATH="/home/user/data_pipeline_project:$PYTHONPATH"*


VÃ©rifiez la variable d'environnement :

<pre><code>echo $PYTHONPATH</code></pre>


### MÃ©thode permanente

Pour que cette modification soit persistante, ajoutez la ligne suivante Ã  la fin de votre fichier `~/.bashrc` :

<pre><code>source ~/.bashrc</code></pre>


# Project Structure
<pre><code>
ðŸ“¦ DATA_PIPELINE_PROJECT  
â”œâ”€â”€ ðŸ“‚ .github  
â”‚   â””â”€â”€ ðŸ“‚ workflows  
â”‚       â””â”€â”€ ðŸ“„ python-app.yml  
â”œâ”€â”€ ðŸ“‚ dags  
â”‚   â”œâ”€â”€ ðŸ“„ __init__.py  
â”‚   â””â”€â”€ ðŸ“„ data_pipeline_dag.py  
â”œâ”€â”€ ðŸ“‚ data  
â”‚   â”œâ”€â”€ ðŸ“„ clinical_trials.csv  
â”‚   â”œâ”€â”€ ðŸ“„ drugs.csv  
â”‚   â”œâ”€â”€ ðŸ“„ pubmed.csv  
â”‚   â””â”€â”€ ðŸ“„ pubmed.json  
â”œâ”€â”€ ðŸ“‚ sql_queries  
â”‚   â”œâ”€â”€ ðŸ“„ query_1  
â”‚   â””â”€â”€ ðŸ“„ query_2  
â”œâ”€â”€ ðŸ“‚ src  
â”‚   â”œâ”€â”€ ðŸ“‚ ad_hoc  
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ __init__.py  
â”‚   â”‚   â””â”€â”€ ðŸ“„ ad_hoc.py  
â”‚   â”œâ”€â”€ ðŸ“‚ data_extract  
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ __init__.py  
â”‚   â”‚   â””â”€â”€ ðŸ“„ extract.py  
â”‚   â”œâ”€â”€ ðŸ“‚ data_load  
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ __init__.py  
â”‚   â”‚   â””â”€â”€ ðŸ“„ load.py  
â”‚   â”œâ”€â”€ ðŸ“‚ data_transform  
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ __init__.py  
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ data_cleaning.py  
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ data_processing.py  
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ drug_mentions.py  
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ relationships.py  
â”‚   â”‚   â”œâ”€â”€ ðŸ“‚ utils  
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ __init__.py  
â”‚   â”‚   â”‚   â””â”€â”€ ðŸ“„ utils.py  
â”‚   â””â”€â”€ ðŸ“„ main.py  
â”œâ”€â”€ ðŸ“‚ tests  
â”‚   â””â”€â”€ ðŸ“‚ unit  
â”‚       â”œâ”€â”€ ðŸ“„ test_data_cleaning.py  
â”‚       â”œâ”€â”€ ðŸ“„ test_data_processing.py  
â”‚       â”œâ”€â”€ ðŸ“„ test_data_transform_utils.py  
â”‚       â”œâ”€â”€ ðŸ“„ test_drug_mentions.py  
â”‚       â”œâ”€â”€ ðŸ“„ test_extract.py  
â”‚       â”œâ”€â”€ ðŸ“„ test_relationships.py  
â”‚       â””â”€â”€ ðŸ“„ test_transform.py  
â”œâ”€â”€ ðŸ“„ .flake8  
â”œâ”€â”€ ðŸ“„ .gitignore  
â”œâ”€â”€ ðŸ“„ Makefile  
â”œâ”€â”€ ðŸ“„ POUR_ALLER_PLUS_LOIN.md  
â”œâ”€â”€ ðŸ“„ README.md  
â”œâ”€â”€ ðŸ“„ config.py  
â”œâ”€â”€ ðŸ“„ pyproject.toml  
â”œâ”€â”€ ðŸ“„ pytest.ini  
â””â”€â”€ ðŸ“„ requirements.txt  

</code></pre>

### Executer tous les tests
Se placer dans le reperoire de votre projet : /home/user/data_pipeline_project*
<pre><code>pytest</code></pre>


### Executer un test spÃ©cifique
 Se placer dans le reperoire de test : *cd /home/user/data_pipeline_project/tests/unit*
<pre><code>
  pytest name_of_the_test.py    
</code></pre>

### Executer le programme (avec le programme main)
 Se placer dans le reperoire src de votre project : *cd /home/user/data_pipeline_project/src*
<pre><code>
  pyton main.py 
</code></pre>

###  outputs
2 fichiers sont gÃ©nÃ©rÃ©s dans le dossier output ( crÃ©e par le programme) : */home/user/data_pipeline/output*
Les deux fichiers sont chacun dans un dossier : link_graph pour *drug_mentions_graph.json* et ad_hoc pour *most_mentioned_journal.json*
<pre><code>
   home/user/data_pipeline/output/link_graph/drug_mentions_graph.json
   home/user/data_pipeline/output/ad_hoc/most_mentioned_journal.json
</code></pre>

###  Executer le Dag
Se placer dans le reperoire de votre projet : */home/user/data_pipeline_project* et executer le MakeFile
<pre><code>
   make
</code></pre>

###  VÃ©rifier les variables d'environement de votre systÃ¨me et les modifer si necessaire avec les commandes ci dessous
Se placer dans le reperoire de votre projet : */home/user/data_pipeline_project* et executer le MakeFile
<pre><code>
   echo $AIRFLOW_HOME
   echo $PATH
   export AIRFLOW_HOME=/home/user/data_pipeline_project/airflow
   export PATH=/home/user/data_pipeline_project/venv/bin:$PATH
</code></pre>

En cas de problem stop airflow
<pre><code>
  make airflow-stop
</code></pre>

Relancer airflow avec la cammande make : (la commande *make* dÃ©marre airflow grace Ã  la commande make *airflow-start*)
<pre><code>
  make
</code></pre>

###  Ouvrir le navigateur avec l'url : http://localhost:8080/home
### Aller sur le dag data_pipeline_dag avec l'url :  http://localhost:8080/dags/data_pipeline_dag/grid
### Lancer le job : avec le boutton trigger DAG
### Suivre l'execution du job

###  outputs
2 fichiers sont gÃ©nÃ©rÃ©s dans le dossier output ( crÃ©e par le programme) : */home/user/data_pipeline/output*
Les deux fichiers sont chacun dans un dossier : link_graph pour *drug_mentions_graph.json* et ad_hoc pour *most_mentioned_journal.json*
<pre><code>
   home/user/data_pipeline/output/link_graph/drug_mentions_graph.json
   home/user/data_pipeline/output/ad_hoc/most_mentioned_journal.json
</code></pre>


###  Pour aller plus loin
[RÃ©ponse sur la question pour aller plus loin : cliquez ici ](POUR_ALLER_PLUS_LOIN.md)
